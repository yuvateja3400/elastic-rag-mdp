# Elastic RAG MDP

A modular **Retrieval-Augmented Generation (RAG)** system built with **Elasticsearch**, **FastAPI**, and **Streamlit**, using open-source LLMs.  
This project was developed as part of an internship assignment and follows industry standards for modular design, reproducibility, and deployment.

---

## ğŸš€ Features
- Ingests PDFs from Google Drive or local folder
- Indexes text chunks into Elasticsearch with:
  - **BM25** (keyword search)
  - **ELSER** (sparse embeddings)
  - **Dense embeddings** (Sentence Transformers)
- Hybrid retrieval (Reciprocal Rank Fusion)
- Answer generation with open LLMs (HuggingFace / Ollama)
- FastAPI backend (`/query`, `/ingest`, `/healthz`)
- Streamlit UI for interactive queries
- Kibana dashboard for inspecting indices & embeddings
- Modular Python package structure
- Dockerized setup for reproducibility

---

## ğŸ“‚ Project Structure
```
elastic-rag-mdp/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py       # centralized settings
â”‚   â”œâ”€â”€ ingestion.py    # PDF text extraction + chunking
â”‚   â”œâ”€â”€ indexing.py     # Elasticsearch index + insert
â”‚   â”œâ”€â”€ retrieval.py    # ELSER, dense, BM25, hybrid
â”‚   â”œâ”€â”€ generation.py   # LLM prompt + response
â”‚   â”œâ”€â”€ guardrails.py   # safety and grounded answers
â”‚   â”œâ”€â”€ api.py          # FastAPI routes
â”‚   â””â”€â”€ ui.py           # Streamlit app
â”œâ”€â”€ tests/              # unit tests
â”œâ”€â”€ data/               # PDFs
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup

### 1. Clone repo
```bash
git clone https://github.com/<your-username>/elastic-rag-mdp.git
cd elastic-rag-mdp
```

### 2. Create virtual environment
```bash
python -m venv .venv
source .venv/bin/activate   # Mac/Linux
# .venv\Scripts\activate    # Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Configure environment
Copy `.env.example` â†’ `.env` and update values if needed:
```bash
cp .env.example .env
```

---

## ğŸ³ Docker Setup

### Start services
```bash
docker compose up --build
```

- Elasticsearch â†’ [http://localhost:9200](http://localhost:9200)  
- Kibana â†’ [http://localhost:5601](http://localhost:5601)  
- FastAPI â†’ [http://localhost:8000/docs](http://localhost:8000/docs)  
- Streamlit â†’ [http://localhost:8501](http://localhost:8501)  

---

## ğŸ” Example Workflow

1. **Ingest PDFs**  
   Place your documents inside `data/pdfs/`.  
   Start services:  
   ```bash
   docker compose up --build
   ```

2. **Index Documents**  
   - Trigger ingestion via API (FastAPI â†’ Streamlit will use this under the hood):  
     ```bash
     curl -X POST "http://localhost:8000/ingest"
     ```
   - Elasticsearch will store the chunks with BM25, ELSER, and dense embeddings.

3. **Ask Questions**  
   - Open **Streamlit UI** â†’ [http://localhost:8501](http://localhost:8501)  
   - Type your question in the input box.  
   - The answer is generated by the LLM and citations are shown (title + snippet).  

4. **Inspect Index and Embeddings (for debugging)**  
   - Open **Kibana** â†’ [http://localhost:5601](http://localhost:5601)  
   - Explore the `rag_documents` index.  
   - You can see stored fields:  
     - `text` (raw chunk)  
     - `text_expansion` (ELSER sparse vector)  
     - `dense_vector` (dense embeddings)  
     - metadata (filename, chunk_id, etc.)  

ğŸ‘‰ In practice:  
- **Streamlit = user-facing interface for Q&A**  
- **Kibana = developer-facing interface to validate embeddings and search quality**  

---

## ğŸ§ª Testing
Run unit tests:
```bash
pytest tests/
```

---

## ğŸ“œ License
MIT License
